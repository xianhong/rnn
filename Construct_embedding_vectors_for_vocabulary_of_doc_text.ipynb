{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split `glove.6B.300d.txt` file vertically into two files:`words` and `vectors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat glove.6B.300d.txt|cut -d ' ' -f 1 > words\n",
    "!cat glove.6B.300d.txt|cut -d ' ' --complement -f 1 > vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import collections\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fable_text = \"\"\"\n",
    "long ago , the mice had a general council to consider what measures\n",
    "they could take to outwit their common enemy , the cat . some said\n",
    "this , and some said that but at last a young mouse got up and said\n",
    "he had a proposal to make , which he thought would meet the case . \n",
    "you will all agree , said he , that our chief danger consists in the\n",
    "sly and treacherous manner in which the enemy approaches us . now , \n",
    "if we could receive some signal of her approach , we could easily\n",
    "escape from her . i venture , therefore , to propose that a small\n",
    "bell be procured , and attached by a ribbon round the neck of the cat\n",
    ". by this means we should always know when she was about , and could\n",
    "easily retire while she was in the neighbourhood . this proposal met\n",
    "with general applause , until an old mouse got up and said that is\n",
    "all very well , but who is to bell the cat ? the mice looked at one\n",
    "another and nobody spoke . then the old mouse said it is easy to\n",
    "propose impossible remedies .\n",
    "\"\"\"\n",
    "# Replace the carriage return with space.\n",
    "fable_text = fable_text.replace('\\n','')\n",
    "\n",
    "#this function puts all the words in a single column vector within a numpy array\n",
    "\n",
    "def read_data(raw_text):\n",
    " content = raw_text\n",
    " content = content.split() #splits the text by spaces (default split character)\n",
    " content = np.array(content)\n",
    " content = np.reshape(content, [-1, ])\n",
    " return content\n",
    "\n",
    "training_data = read_data(fable_text)\n",
    "\n",
    "#Create dictionary and reverse dictionary with word ids\n",
    "\n",
    "def build_dictionaries(words):\n",
    "    count = collections.Counter(words).most_common() #creates list of word/count pairs;\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary) #len(dictionary) increases each iteration\n",
    "        reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return dictionary, reverse_dictionary\n",
    "\n",
    "dictionary, reverse_dictionary = build_dictionaries(training_data)\n",
    "\n",
    "doc_vocab_size = len(dictionary) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct embedding vectors for vocabulary of doc text\n",
    "### Extract embedding vectors for words  in Glove data file by looking up two hash tables (from file)  :\n",
    "lookup index of word by word (using `words` file);\n",
    "\n",
    "lookup embedding word vector by word index (using  `vectors` file);\n",
    "### Use random embedding vectors for words NOT  included in Glove data file.\n",
    "### Save the numpy array of constructed embedding vectors to `embedding.npy` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.tables_initializer()\n",
    "\n",
    "features = tf.convert_to_tensor([reverse_dictionary[i] for i in range(doc_vocab_size)],dtype=tf.string)\n",
    "table = tf.contrib.lookup.index_table_from_file(\n",
    "    vocabulary_file=\"words\", num_oov_buckets=0)\n",
    "ids = table.lookup(features)\n",
    "\n",
    "table2 = tf.contrib.lookup.index_to_string_table_from_file(\n",
    "    vocabulary_file=\"vectors\")\n",
    "lines = table2.lookup(ids)\n",
    "\n",
    "embedding_dim = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vector (line):\n",
    "    RECORD_DEFAULTS = [0.0]*embedding_dim\n",
    "    vector = tf.cond(tf.equal(tf.constant('UNK'),line),\n",
    "            lambda:tf.random.uniform([embedding_dim,],minval=-0.2, maxval=0.2),\n",
    "            lambda:tf.convert_to_tensor(tf.decode_csv(line, RECORD_DEFAULTS,field_delim=' ')))\n",
    "    return vector\n",
    "\n",
    "embedding = tf.map_fn(make_vector,lines,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('embedding.npy', embedding.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
